# -*- coding: utf-8 -*-
"""MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jsErdZgFi4RMXTHO-YvYysfxmtQUbwVc
"""

from sklearn.datasets import load_digits

digits=load_digits()

import numpy as np

x=digits.data
y=digits.target

type(x)
print(x.shape)
print(y.shape)

#from sklearn.preprocessing import OneHotEncoder
#ohe = OneHotEncoder()
#y = ohe.fit_transform(y.reshape(1,-1)).toarray()
#y.shape
# mapping = [i for i in range(10)]
y_vec = []
for lbl in y:
  temp = [0 for _ in range(10)]
  temp[int(lbl)] = 1
  y_vec.append(temp)
y_vec = np.array(y_vec)
y_vec.shape

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(digits.data,y_vec,test_size = 0.1)

#Dependencies
import keras
from keras.models import Sequential
from keras.layers import Dense# Neural network
model = Sequential()
model.add(Dense(64, input_dim=64, activation="relu"))
model.add(Dense(16, activation="relu"))
model.add(Dense(10, activation="softmax"))
model.summary()

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs=100, batch_size=64)

