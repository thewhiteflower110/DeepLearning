{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Meow!!!.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh0-rxNZgm_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7e97d4df-2851-4478-b7dc-05702809081f"
      },
      "source": [
        "import keras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU1RvJ8LhVxv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6d39131c-8e22-4d33-b7d7-ce80bad0686c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QyhMRqtiTBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "encoding = 'unicode_escape'\n",
        "\n",
        "file_id = '1PIKSNOsgJ_J9QQBnPUJ759sor9cM2p88'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('data.zip') \n",
        "!unzip data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2x5UzSVijT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLtm34NPjuob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqQahfdHkswq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ab9e5c26-4e8a-470c-8274-bff6f838c16a"
      },
      "source": [
        "path='/content/test_set/test_set/cats/cat.4001.jpg'\n",
        "cv2.imread(path).shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(415, 498, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CVADSSYjIab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path='/content/training_set/training_set/dogs/*.jpg'\n",
        "files=glob.glob(path)\n",
        "for i in files:\n",
        "  #print(i)\n",
        "  #break\n",
        "  img=cv2.imread(i)\n",
        "  #print(img)\n",
        "  #break\n",
        "  img=cv2.resize(img,(50,50))\n",
        "  cv2.imwrite(i,img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJDIwo5MmYX1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2ebf7ecd-c5f0-4581-f848-755b730f676c"
      },
      "source": [
        "path='/content/training_set/training_set/dogs/dog.1001.jpg'\n",
        "cv2.imread(path).shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 50, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3m7N55ylAAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path='/content/training_set/training_set/cats/*.jpg'\n",
        "files=glob.glob(path)\n",
        "for i in files:\n",
        "  #print(i)\n",
        "  #break\n",
        "  img=cv2.imread(i)\n",
        "  #print(img)\n",
        "  #break\n",
        "  img=cv2.resize(img,(50,50))\n",
        "  cv2.imwrite(i,img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiE3dq2SmWu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path='/content/test_set/test_set/cats/*.jpg'\n",
        "files=glob.glob(path)\n",
        "for i in files:\n",
        "  #print(i)\n",
        "  #break\n",
        "  img=cv2.imread(i)\n",
        "  #print(img)\n",
        "  #break\n",
        "  img=cv2.resize(img,(50,50))\n",
        "  cv2.imwrite(i,img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVvJqj1rocTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path='/content/test_set/test_set/dogs/*jpg'\n",
        "files=glob.glob(path)\n",
        "for i in files:\n",
        "  #print(i)\n",
        "  #break\n",
        "  img=cv2.imread(i)\n",
        "  #print(img)\n",
        "  #break\n",
        "  img=cv2.resize(img,(50,50))\n",
        "  cv2.imwrite(i,img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0Q2_eQooknA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "aa375f95-2b4a-4fe7-f3dc-7ed35cb4bb47"
      },
      "source": [
        "from keras import optimizers\n",
        "from keras.models import Model,Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten\n",
        "classifier=Sequential()\n",
        "classifier.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(50,50,3)))\n",
        "#model.add(Conv2D(32, kernel_size=3, activation=’relu’))\n",
        "classifier.add(Conv2D(16, kernel_size=3, activation='relu'))\n",
        "#model.add(Conv2D(8, kernel_size=3, activation=’relu’))\n",
        "#model.add(Conv2D(4, kernel_size=3, activation=’relu’))\n",
        "classifier.add(Flatten())\n",
        "classifier.add(Dense(2, activation='softmax'))\n",
        "classifier.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 48, 48, 64)        1792      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 46, 46, 16)        9232      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 33856)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 67714     \n",
            "=================================================================\n",
            "Total params: 78,738\n",
            "Trainable params: 78,738\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHPLi9_Cs2tt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx-uUOiUrGq4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a5328571-2d9b-4897-f156-1cc43bec4d25"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "adam = Adam(epsilon = 0.01)\n",
        "classifier.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "#print(test_datagen)\n",
        "\n",
        "train_folder = '/content/training_set/training_set' \n",
        "test_folder = '/content/test_set/test_set'\n",
        "\n",
        "\n",
        "train_set = train_datagen.flow_from_directory(train_folder,\n",
        "                                              classes=['dogs','cats'],\n",
        "                                              target_size=(50, 50),\n",
        "                                              batch_size=32,class_mode='categorical',\n",
        "                                              color_mode='rgb',\n",
        "                                              seed=5)\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(test_folder,\n",
        "                                            classes=['dogs','cats'],\n",
        "                                            target_size=(50, 50),\n",
        "                                            batch_size=32,\n",
        "                                            class_mode='categorical',\n",
        "                                            color_mode='rgb',\n",
        "                                            seed=5)\n",
        "\n",
        "\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8005 images belonging to 2 classes.\n",
            "Found 2023 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeZgDvdCsXLA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "403586fc-9dc0-4dea-bfaa-2f10cc7e6627"
      },
      "source": [
        "history = classifier.fit_generator(train_set,steps_per_epoch=1200,epochs=5,validation_data=test_set,validation_steps=300)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1200/1200 [==============================] - 316s 263ms/step - loss: 0.6268 - accuracy: 0.6419 - val_loss: 0.6352 - val_accuracy: 0.6625\n",
            "Epoch 2/5\n",
            "1200/1200 [==============================] - 310s 258ms/step - loss: 0.4914 - accuracy: 0.7592 - val_loss: 0.6386 - val_accuracy: 0.6855\n",
            "Epoch 3/5\n",
            "1200/1200 [==============================] - 316s 263ms/step - loss: 0.3358 - accuracy: 0.8544 - val_loss: 0.6943 - val_accuracy: 0.6925\n",
            "Epoch 4/5\n",
            "1200/1200 [==============================] - 312s 260ms/step - loss: 0.1748 - accuracy: 0.9354 - val_loss: 1.5303 - val_accuracy: 0.6903\n",
            "Epoch 5/5\n",
            "1200/1200 [==============================] - 317s 264ms/step - loss: 0.0556 - accuracy: 0.9876 - val_loss: 1.5097 - val_accuracy: 0.6986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRjn37EUtqpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}